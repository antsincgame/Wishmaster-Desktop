[package]
name = "wishmaster-desktop"
version = "1.0.0"
description = "Local AI Assistant with Voice Cloning"
authors = ["Wishmaster Team"]
license = "MIT"
repository = "https://github.com/antsincgame/Wishmaster-Desktop"
edition = "2021"

[build-dependencies]
tauri-build = { version = "2", features = [] }

[dependencies]
tauri = { version = "2", features = [] }
tauri-plugin-dialog = "2"
serde = { version = "1", features = ["derive"] }
serde_json = "1"
tokio = { version = "1", features = ["full"] }
rusqlite = { version = "0.31", features = ["bundled"] }
dirs = "5"
once_cell = "1"
base64 = "0.21"
thiserror = "1.0"  # Custom error types

# LLM - native llama.cpp bindings (CPU by default, CUDA optional)
llama-cpp-2 = "0.1"

# Embeddings for semantic search / RAG
# Pin to 3.x for stable InitOptions API
fastembed = "3"

# Audio - placeholder (add cpal + hound later for voice features)
# cpal = "0.15"
# hound = "3.5"

# STT - placeholder (add whisper-rs later)
# whisper-rs = "0.10"

# TTS - placeholder (add ort later for ONNX models)
# ort = "2.0"

[features]
default = ["custom-protocol"]
custom-protocol = ["tauri/custom-protocol"]

# CUDA acceleration (requires CUDA toolkit)
cuda = ["llama-cpp-2/cuda"]

[dev-dependencies]
tempfile = "3.10"  # For creating temp directories in tests

[profile.release]
panic = "abort"
codegen-units = 1
lto = true
opt-level = "s"
strip = false  # Required for Tauri bundler
